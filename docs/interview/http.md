---
outline: deep
---

## 使用 CDN 的意义

::: details
使用 CDN（内容分发网络）有以下几个主要意义和优势：

- **提高加载速度**:
  - CDN 将静态资源（如图片、JavaScript、CSS 文件等）分布在多个地理位置的服务器上，用户可以从离他们最近的服务器获取资源，从而减少延迟，提高加载速度。

- **减轻源服务器负担**:
  - 通过将静态资源托管在 CDN 上，可以减轻源服务器的负担，避免因高流量导致的性能瓶颈。这使得源服务器可以更专注于处理动态请求。

- **高可用性和冗余**:
  - CDN 提供冗余和故障转移机制，即使某个节点出现故障，用户仍然可以从其他节点获取资源，确保网站的高可用性。

- **全球覆盖**:
  - CDN 通常在全球范围内部署多个节点，能够为全球用户提供一致的访问体验，特别是在跨国或跨地区的应用中。

- **安全性增强**:
  - CDN 提供 DDoS 防护、Web 应用防火墙（WAF）等安全功能，帮助保护网站免受恶意攻击。

- **缓存机制**:
  - CDN 可以缓存静态资源，减少源服务器的请求次数，提高响应速度。缓存策略可以根据内容的更新频率进行配置。

- **SEO 优势**:
  - 更快的加载速度和更好的用户体验可以提高网站的搜索引擎排名，进而提升网站的可见性。

- **简化内容管理**:
  - 使用 CDN 可以简化静态资源的管理和分发，开发者可以专注于应用的核心逻辑，而不必担心资源的分发和优化。

- **支持大规模流量**:
  - 在流量高峰期，CDN 可以有效地处理大量并发请求，确保网站在高流量情况下仍能保持良好的性能。

- **便于版本控制**:
  - CDN 可以轻松管理不同版本的静态资源，开发者可以通过版本号来控制资源的更新和缓存。

:::

## http三次握手四次挥手的过程

:::details

- 三次握手过程
  1. **客户端发送SYN**：
     - 客户端向服务器发送一个SYN（同步）包，表示请求建立连接。此时，客户端处于SYN_SEND状态。

  2. **服务器回应SYN-ACK**：
     - 服务器收到SYN包后，回应一个SYN-ACK包，表示同意建立连接。此时，服务器处于SYN_RECEIVED状态。

  3. **客户端发送ACK**：
     - 客户端收到SYN-ACK包后，发送一个ACK（确认）包，表示连接建立成功。此时，客户端和服务器都进入ESTABLISHED状态，连接建立完成。
- 四次挥手过程

  1. **客户端发送FIN**：
     - 客户端向服务器发送一个FIN（结束）包，表示希望关闭连接。此时，客户端进入FIN_WAIT_1状态。

  2. **服务器回应ACK**：
     - 服务器收到FIN包后，发送一个ACK包，确认收到FIN。此时，服务器进入CLOSE_WAIT状态，客户端进入FIN_WAIT_2状态。

  3. **服务器发送FIN**：
     - 服务器准备关闭连接时，发送一个FIN包给客户端，表示也希望关闭连接。此时，服务器进入LAST_ACK状态。

  4. **客户端回应ACK**：
     - 客户端收到FIN包后，发送一个ACK包，确认收到FIN。此时，客户端进入TIME_WAIT状态，等待一段时间以确保服务器收到ACK后，最终进入CLOSED状态，连接关闭。

- **三次握手**的目的是为了确保双方都准备好进行数据传输，建立可靠的TCP连接。
- **四次挥手**的过程用于安全地关闭连接，确保所有数据都已传输完毕，避免数据丢失。

:::

## http1.0与http2.0的区别

:::details
HTTP/1.0是无状态的，每个请求都需要建立新的连接，而HTTP/2.0支持多路复用，可以在一个连接上同时处理多个请求，从而减少延迟。

- HTTP/1.0每次请求都需要重新建立TCP连接，增加了延迟。
- HTTP/2.0通过多路复用技术，允许多个请求共享同一个连接，减少了连接建立的开销。
- HTTP/2.0还支持头部压缩，进一步减少了数据传输的大小，提高了传输效率。

:::

## HTTP2.0 有哪些新特性

::: details
HTTP/2.0 引入了多项新特性，以提高网络性能和用户体验。以下是一些主要的新特性：

- **二进制分帧**:
  - HTTP/2.0 将数据传输从文本格式转换为二进制格式，使用帧（frame）来传输数据。这种方式更高效，减少了解析开销。

- **多路复用**:
  - 允许在单个 TCP 连接上并行发送多个请求和响应，而不需要为每个请求建立新的连接。这减少了延迟和网络拥塞，提高了资源利用率。

- **头部压缩**:
  - HTTP/2.0 使用 HPACK 算法对 HTTP 头部进行压缩，减少了头部的大小，从而降低了带宽消耗和延迟。

- **服务器推送**:
  - 服务器可以主动向客户端推送资源，而不需要客户端请求。这意味着在客户端请求某个资源时，服务器可以同时推送相关的资源（如 CSS 和 JavaScript 文件），提高页面加载速度。

- **流量优先级**:
  - HTTP/2.0 允许客户端为请求设置优先级，服务器可以根据优先级来安排资源的发送顺序，从而优化加载性能。

- **单一连接**:
  - HTTP/2.0 通过使用单一的 TCP 连接来处理多个请求，减少了连接建立和关闭的开销，降低了延迟。

- **更好的错误处理**:
  - HTTP/2.0 提供了更丰富的错误处理机制，允许更细粒度的错误状态码和更清晰的错误信息。

- **流的概念**:
  - HTTP/2.0 引入了流的概念，流是一个有序的字节序列，允许在同一连接上进行多个流的并行处理。

- HTTP/2.0 通过引入二进制分帧、多路复用、头部压缩、服务器推送等新特性，显著提高了网络性能和用户体验。这些特性使得 Web 应用能够更快地加载和响应用户请求。
:::

## HTTP/3.0 有哪些新特性

::: details
HTTP/3.0 是基于 QUIC（Quick UDP Internet Connections）协议的最新版本，带来了多项新特性和改进，以提高网络性能和安全性。以下是一些主要的新特性：

- **基于 UDP 的传输**:
  - HTTP/3.0 使用 QUIC 协议，基于 UDP 而非 TCP。这使得连接建立和数据传输更加高效，减少了延迟。

- **零延迟连接建立**:
  - QUIC 支持零轮次连接建立（0-RTT），允许客户端在重新连接时立即发送数据，而无需等待连接建立完成，从而减少延迟。

- **多路复用**:
  - 类似于 HTTP/2.0，HTTP/3.0 也支持多路复用，但由于使用了 QUIC，避免了 TCP 中的队头阻塞问题。多个流可以在同一连接中并行传输，而不会相互干扰。

- **内置加密**:
  - QUIC 协议内置了加密功能，所有的 HTTP/3.0 流量都通过 TLS 1.3 加密，提供更高的安全性和隐私保护。

- **更好的拥塞控制**:
  - QUIC 提供了更灵活的拥塞控制机制，能够更好地适应网络条件，优化数据传输效率。

- **连接迁移**:
  - QUIC 支持连接迁移，允许客户端在网络环境变化时（如从 Wi-Fi 切换到移动数据）保持连接，而无需重新建立连接。

- **流的优先级**:
  - HTTP/3.0 允许对流进行优先级设置，优化资源的传输顺序，提高用户体验。

- **更快的错误恢复**:
  - QUIC 提供了更快的错误恢复机制，能够在数据包丢失时更迅速地重传数据，减少延迟。

- HTTP/3.0 通过引入基于 UDP 的 QUIC 协议，显著提高了网络性能和安全性。其新特性如零延迟连接建立、多路复用、内置加密等，使得 Web 应用能够更快、更安全地响应用户请求。
:::

## HTTP/3.0 为什么要使用 UDP

::: details
HTTP/3.0 选择使用 UDP（用户数据报协议）而非传统的 TCP（传输控制协议），主要是为了提高网络性能和用户体验。以下是使用 UDP 的几个主要原因：

- **减少连接建立延迟**:
  - UDP 不需要像 TCP 那样进行三次握手来建立连接，这意味着可以更快地开始数据传输。QUIC 协议通过零轮次连接建立（0-RTT）进一步减少了延迟，允许客户端在重新连接时立即发送数据。

- **多路复用**:
  - UDP 允许在同一连接上并行传输多个数据流，而不会出现 TCP 中的队头阻塞问题。在 TCP 中，如果一个数据包丢失，后续的数据包必须等待重传完成才能继续传输，而在 UDP 中，多个流可以独立处理，提升了传输效率。

- **更灵活的拥塞控制**:
  - QUIC 协议在 UDP 的基础上实现了更灵活的拥塞控制机制，能够根据网络状况动态调整数据传输速率，从而优化性能。

- **连接迁移**:
  - UDP 支持连接迁移，允许客户端在网络环境变化时（如从 Wi-Fi 切换到移动数据）保持连接，而无需重新建立连接。这对于移动设备用户尤其重要，可以提供更流畅的体验。

- **内置加密**:
  - QUIC 协议在 UDP 的基础上内置了加密功能，所有的 HTTP/3.0 流量都通过 TLS 1.3 加密，提供更高的安全性和隐私保护。

- **更快的错误恢复**:
  - UDP 的设计使得在数据包丢失时，QUIC 可以更迅速地重传数据，减少延迟，提高用户体验。

- 使用 UDP 使得 HTTP/3.0 能够在连接建立、数据传输和错误恢复等方面提供更高的性能和更低的延迟。这些优势使得 HTTP/3.0 更适合现代网络应用，尤其是在高延迟和不稳定的网络环境中。
:::

## HTTP/3.0 使用 UDP 如何保证安全性

::: details
HTTP/3.0 使用 UDP（用户数据报协议）作为传输层协议，虽然 UDP 本身不提供安全性，但 QUIC 协议在其基础上实现了多种安全机制，以确保数据传输的安全性。以下是 HTTP/3.0 保证安全性的主要方式：

- **内置加密**:
  - QUIC 协议内置了加密功能，所有的 HTTP/3.0 流量都通过 TLS 1.3 加密。这意味着数据在传输过程中是加密的，防止了中间人攻击和数据窃听。

- **身份验证**:
  - QUIC 使用 TLS 1.3 的身份验证机制，确保通信双方的身份是可信的。通过证书和密钥交换，客户端和服务器可以验证彼此的身份。

- **数据完整性**:
  - QUIC 通过加密和消息认证码（MAC）来确保数据的完整性。任何在传输过程中被篡改的数据都会被检测到，从而防止数据被恶意修改。

- **抗重放攻击**:
  - QUIC 设计中包含了防止重放攻击的机制，确保每个数据包都是唯一的，防止攻击者重放旧的数据包。

- **快速恢复**:
  - QUIC 的设计允许快速恢复丢失的数据包，结合加密机制，确保在数据包丢失时不会泄露敏感信息。

- **连接迁移**:
  - QUIC 支持连接迁移，允许客户端在网络环境变化时保持连接，同时确保在迁移过程中数据的安全性和完整性。

- HTTP/3.0 通过 QUIC 协议在 UDP 的基础上实现了内置加密、身份验证、数据完整性保护和抗重放攻击等多种安全机制，确保了数据传输的安全性。这使得 HTTP/3.0 能够在提供高性能的同时，保障用户数据的安全和隐私。
:::

## 前端开发时的安全处理都有哪些？

::: details
在前端开发中，确保应用的安全性是至关重要的。以下是一些常见的安全处理措施：

- **输入验证**:
  - 对用户输入进行严格的验证和过滤，防止恶意数据的注入。可以使用正则表达式、白名单等方式进行验证。

- **输出编码**:
  - 在将用户输入的数据输出到页面时，进行适当的编码（如 HTML 编码、URL 编码等），防止跨站脚本攻击（XSS）。

- **使用 HTTPS**:
  - 确保所有的网络请求都通过 HTTPS 进行加密，防止数据在传输过程中被窃取或篡改。

- **内容安全策略（CSP）**:
  - 实施内容安全策略，限制页面可以加载的资源，防止 XSS 攻击和数据注入。

- **防止跨站请求伪造（CSRF）**:
  - 使用 CSRF 令牌来验证请求的合法性，确保请求是由用户的浏览器发起的，而不是恶意网站。

- **安全的 Cookie 设置**:
  - 设置 HttpOnly 和 Secure 属性，防止 JavaScript 访问 Cookie，并确保 Cookie 仅通过 HTTPS 传输。

- **避免信息泄露**:
  - 不在前端代码中暴露敏感信息，如 API 密钥、数据库连接字符串等。使用环境变量和后端代理来保护敏感数据。

- **使用安全的第三方库**:
  - 定期更新和审查使用的第三方库，确保没有已知的安全漏洞。使用工具（如 npm audit）来检查依赖项的安全性。

- **限制用户权限**:
  - 根据用户角色和权限限制访问敏感功能和数据，确保用户只能访问其被授权的资源。

- **监控和日志记录**:
  - 实施监控和日志记录，及时发现和响应潜在的安全事件和攻击。

- 前端开发中的安全处理措施包括输入验证、输出编码、使用 HTTPS、实施内容安全策略、保护 Cookie、避免信息泄露等。通过采取这些措施，可以有效提高应用的安全性，保护用户数据和隐私。
:::

## 缓存

### 缓存设置

:::details
在Web开发中，缓存的设置可以由多个层面来进行，常见的包括：

1. **Web服务器：**
   - Nginx：可以通过配置文件设置缓存策略，例如使用 `proxy_cache`、`expires` 和 `cache-control` 等指令来控制静态资源和动态请求的缓存。
   - Apache：同样可以通过配置文件设置缓存，使用模块如 mod_cache 和 mod_expires。

2. **应用服务器：**
   - 在应用层（如Node.js、Java、Python等）中，开发者可以通过代码设置缓存策略，控制数据的缓存和过期时间。

3. **CDN（内容分发网络）：**
   - CDN提供商（如Cloudflare、Akamai等）通常会提供缓存设置，允许用户配置缓存策略，以提高内容的分发速度和减少源服务器的负担。

4. **浏览器：**
   - 开发者可以通过HTTP响应头（如 `Cache-Control`、`Expires`、`ETag` 等）来指示浏览器如何缓存资源。
  
5. **代理服务器：**
   - 在网络中，代理服务器也可以设置缓存策略，以提高请求的响应速度。

- 综上所述，缓存的设置可以由Nginx、其他Web服务器、应用服务器、CDN、浏览器和代理服务器等多个层面来进行。具体的设置方式和策略取决于应用的需求和架构设计。

:::

### 缓存配置的优先级

:::details
在浏览器缓存和服务器缓存的配置中，通常情况下，服务器缓存配置的优先级更高。以下是一些关键点来说明这一点：

1. **服务器控制：**
   - 服务器通过HTTP响应头（如 `Cache-Control`、`Expires`、`ETag` 等）来指示浏览器如何处理缓存。这些头部信息是浏览器在决定是否使用缓存时的重要依据。
2. **浏览器遵循服务器指令：**
   - 浏览器会遵循服务器的缓存指令。如果服务器设置了不缓存的指令（例如 `Cache-Control: no-store`），浏览器将不会缓存该资源，尽管浏览器本身可能有其他的缓存策略。
3. **缓存策略的冲突：**
   - 如果服务器和浏览器的缓存策略发生冲突，浏览器通常会遵循服务器的指令。例如，如果服务器指示某个资源不应被缓存，而浏览器的默认设置是缓存该资源，浏览器会尊重服务器的设置。
4. **用户设置：**
   - 用户可以在浏览器中手动清除缓存或更改缓存设置，但这些操作通常是在服务器的指令之下进行的。

- **总结**
  - 服务器的缓存配置通常优先于浏览器的缓存配置。服务器通过HTTP响应头控制缓存行为，而浏览器会根据这些指令来决定是否缓存资源。因此，确保服务器正确配置缓存策略是非常重要的。

:::

### 强缓存与协商缓存

:::details
在前端开发中，缓存是提升性能的重要手段。HTTP缓存主要分为强缓存和协商缓存两种机制。

1. 强缓存
  强缓存是指在资源未过期的情况下，浏览器直接使用缓存中的资源，而不向服务器发送请求。强缓存通过HTTP响应头中的`Cache-Control`和`Expires`字段来控制。
   - **Cache-Control**：
     - 用于指定缓存的策略，常见的值包括：
       - `no-cache`：强制重新验证缓存。
       - `no-store`：不缓存任何内容。
       - `max-age=<seconds>`：指定资源的最大缓存时间，单位为秒。
       - `public`：表示响应可以被任何缓存区缓存。
       - `private`：表示响应只能被用户的浏览器缓存。

   - **Expires**：
     - 指定资源的过期时间，过期后需要重新请求。该字段的值为一个HTTP日期格式。
     - 示例：

         ```http
         Cache-Control: max-age=3600
         Expires: Wed, 21 Oct 2023 07:28:00 GMT
         ```

2. 协商缓存
  协商缓存是指在资源过期后，浏览器向服务器发送请求，询问资源是否更新。服务器根据资源的状态决定是否使用缓存。协商缓存通过`Last-Modified`和`ETag`字段来实现。

   - **Last-Modified**：
     - 服务器在响应中返回资源的最后修改时间。浏览器在后续请求中会发送`If-Modified-Since`头，询问资源是否在该时间后被修改。
     - 示例：

         ```http
         Last-Modified: Wed, 21 Oct 2023 07:28:00 GMT
         ```

   - **ETag**：
     - 服务器为资源生成一个唯一标识符（ETag），浏览器在后续请求中会发送`If-None-Match`头，询问资源的ETag是否匹配。
     - 示例：

         ```http
         ETag: "abc123"
         ```

   - **服务器响应**：
     - 如果资源未修改，服务器会返回304 Not Modified状态，浏览器使用缓存的资源。
     - 如果资源已修改，服务器会返回新的资源和200 OK状态。

- 强缓存和协商缓存是HTTP缓存的两种机制。强缓存通过`Cache-Control`和`Expires`控制资源的缓存时间，直接使用缓存；协商缓存通过`Last-Modified`和`ETag`实现与服务器的验证，确保使用最新的资源。合理使用这两种缓存机制可以显著提升Web应用的性能和用户体验。

:::

### Cache-Control 中 `no-cache` 与 `no-store` 的区别

:::details
在 HTTP 的缓存控制中，`Cache-Control` 是一个重要的响应头，用于指示缓存的行为。其中，`no-cache` 和 `no-store` 是两个常用的指令，它们的含义和使用场景有所不同。

1. no-cache

   - **定义**：
     - `no-cache` 指示缓存服务器在使用缓存的响应之前，必须先向源服务器进行验证。也就是说，缓存的内容可以被存储，但在使用之前必须检查其有效性。

   - **使用场景**：
     - 当你希望缓存的内容在每次请求时都进行验证，但仍然希望利用缓存的优势时，可以使用 `no-cache`。例如，某些动态生成的内容可能会频繁变化，但仍然希望在一定时间内使用缓存。

   - **示例**：

     ```http
     Cache-Control: no-cache
     ```

2. no-store

   - **定义**：
     - `no-store` 指示缓存服务器和浏览器不应缓存任何内容。每次请求都必须从源服务器获取最新的内容。

   - **使用场景**：
     - 当你希望确保敏感信息（如用户的个人数据、支付信息等）不被缓存时，可以使用 `no-store`。这对于保护用户隐私和安全非常重要。

   - **示例**：

     ```http
     Cache-Control: no-store
     ```

3. 总结

   - **no-cache**：允许缓存内容，但在使用之前必须进行验证。适用于希望利用缓存但又需要确保内容新鲜的场景。
   - **no-store**：禁止缓存任何内容，每次请求都必须从源服务器获取。适用于需要保护敏感信息的场景。

:::

### 前端网络缓存与资源缓存

:::details
前端网络缓存和资源缓存是提升Web应用性能的重要手段。它们通过减少网络请求和加快资源加载速度，改善用户体验。以下是对前端网络缓存和资源缓存的详细说明。

1. 前端网络缓存
    1. 缓存机制
        - **HTTP缓存**：浏览器会根据HTTP响应头中的缓存控制字段（如`Cache-Control`、`Expires`、`ETag`等）来决定是否使用缓存。
        - **Cache-Control**：用于指定缓存的策略，如`no-cache`、`no-store`、`max-age`等。
        - **Expires**：指定资源的过期时间，过期后需要重新请求。
        - **ETag**：用于验证缓存的有效性，浏览器在请求时会发送`If-None-Match`头，服务器根据ETag判断资源是否更新。

    2. 使用场景
         - **API请求**：对于频繁请求的API，可以使用网络缓存来减少请求次数，提高响应速度。
         - **静态资源**：对于不常变化的静态资源（如图片、CSS、JS文件），可以设置较长的缓存时间，减少加载时间。
2. 资源缓存
    1. 缓存策略
        - **强缓存**：在资源未过期时，直接使用缓存，不向服务器发送请求。通过`Cache-Control`和`Expires`实现。
        - **协商缓存**：在资源过期后，向服务器发送请求，验证资源是否更新。通过`ETag`和`Last-Modified`实现。

    2. 使用场景

       - **CDN加速**：将静态资源托管在CDN上，利用CDN的缓存机制和分布式网络加速资源加载。
       - **Service Worker**：使用Service Worker实现离线缓存和资源预缓存，提升应用的离线体验和加载速度。

    3. 实现方式
      - **HTTP缓存示例**：

      ```javascript
      fetch('/api/data', {
          method: 'GET',
          headers: {
              'Cache-Control': 'max-age=3600', // 1小时缓存
          },
      });
      ```

      - **Service Worker示例**：

      ```javascript
      self.addEventListener('install', (event) => {
          event.waitUntil(
              caches.open('my-cache').then((cache) => {
                  return cache.addAll([
                      '/index.html',
                      '/styles.css',
                      '/script.js',
                  ]);
              })
          );
      });

      self.addEventListener('fetch', (event) => {
          event.respondWith(
              caches.match(event.request).then((response) => {
                  return response || fetch(event.request);
              })
          );
      });
      ```

- 前端网络缓存和资源缓存是提升Web应用性能的关键技术。通过合理配置HTTP缓存、使用CDN和Service Worker等手段，可以有效减少网络请求、加快资源加载速度，从而改善用户体验。

:::

### 图片使用 Base64 的缺点

:::details

使用 Base64 编码图片虽然在某些情况下方便，但也存在一些缺点，主要包括：

1. **文件大小增加**:
   - Base64 编码会使文件大小增加约 33%。这意味着使用 Base64 编码的图片比原始图片文件大，可能导致页面加载速度变慢。

2. **增加初始加载时间**:
   - 将图片嵌入到 HTML 或 CSS 中会导致初始加载时间增加，尤其是在图片较大或数量较多时，可能影响用户体验。

3. **缓存效率低**:
   - 使用 Base64 编码的图片无法单独缓存。每次页面加载时，浏览器都需要重新解析和加载整个 HTML 或 CSS 文件，而不是单独请求图片文件。这可能导致不必要的网络流量和延迟。

4. **可读性差**:
   - Base64 编码的字符串较长，嵌入到代码中会降低代码的可读性和可维护性。调试时也不容易识别和处理。

5. **不适合大图片**:
   - 对于较大的图片，使用 Base64 编码会导致 HTML 或 CSS 文件变得庞大，影响性能。通常不建议对大图片使用 Base64 编码。

6. **影响 SEO**:
   - 搜索引擎可能无法有效解析嵌入的 Base64 图片，影响页面的 SEO 优化。

- 虽然 Base64 编码在某些情况下可以简化资源管理，但其缺点包括文件大小增加、初始加载时间延长、缓存效率低、可读性差、不适合大图片以及可能影响 SEO。在使用 Base64 编码时，需要权衡这些缺点与其带来的便利性。

:::
